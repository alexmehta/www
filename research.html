<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Alexander Mehta</title>
  </head>
  <body>
    <h1>research: transformers and llms. Worth the hype?</h1>
    <p>GPT-3 and ChatGPT have been fairly popular topics. Having research experience in machine learning, but not text-based applications, I was curious how "innovative" OpenAI's GPT really is. I was inspired partially by a tweet by Yann LeCun, one of the pioneers of AI and Machine Learning.</p>
    <div>
    <blockquote class="twitter-tweet"><p lang="en" dir="ltr">To be clear: I&#39;m not criticizing OpenAI&#39;s work nor their claims.<br><br>I&#39;m trying to correct a *perception* by the public &amp; the media who see chatGPT as this incredibly new, innovative, &amp; unique technological breakthrough that is far ahead of everyone else.<br><br>It&#39;s just not.</p>&mdash; Yann LeCun (@ylecun) <a href="https://twitter.com/ylecun/status/1617921903934726144?ref_src=twsrc%5Etfw">January 24, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
    </div>
    <h2>So how innovative is ChatGPT?</h2>

    <p><b>Short answer: it isn't</b></p>
    <h3>Longer answer:</h3>
    <p>This is where I started doing research. I know the seminal paper in text based machine learning approaches is <a href="https://arxiv.org/abs/1706.03762">"Attention is All You Need"</a> in 2017. This paper explains the concept of attention through a new type of model called the "transformer". To skip a bunch of math and computer science, the simplist understanding of the transformer/attention are "a method for a machine to learn what to pay <i>attention</i> to".</p>
    <p>I'm going to skip over technical details and go to results of this new (for 2017) research (I link a bunch of technical papers that I read at the end). The results showed that the model could easily understand and translate from English to German (and vice versa). In simple language, all it was shown was an English word, told to guess what the German output should be, and then told if it was right or wrong</p> 

    <h2>How do we get from 2017 research to chatGPT?</h2>

  </body>
</html>
